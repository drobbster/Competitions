{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60cdff95-e165-4ef7-82bb-be2d3d799248",
    "_uuid": "3fd8e11c1ff348d6b1579a18fe737cec265e04aa"
   },
   "source": [
    "## Company Information:\n",
    "Lending Club is a  peer to peer lending company based in the United States, in which investors provide funds for potential borrowers and investors earn a profit depending on the risk they take (the borrowers credit score). Lending Club provides the \"bridge\" between investors and borrowers. For more basic information about the company please check out the wikipedia article about the company. <br><br>\n",
    "\n",
    "\n",
    "<a src=\"https://en.wikipedia.org/wiki/Lending_Club\"> Lending Club Information </a>\n",
    "\n",
    "\n",
    "## Outline: <br>\n",
    "I. Introduction <br>\n",
    "a) [General Information](#general_information)<br>\n",
    "b) [Similar Distributions](#similar_distributions)<br><br>\n",
    "\n",
    "II. <b>Good Loans vs Bad Loans</b><br>\n",
    "a) [Types of Loans](#types_of_loans)<br>\n",
    "b) [Loans issued by Region](#by_region)<br>\n",
    "c) [A Deeper Look into Bad Loans](#deeper_bad_loans)<br><br>\n",
    "\n",
    "III. <b>The Business Perspective</b><br>\n",
    "a) [Understanding the Operative side of Business](#operative_side)<br>\n",
    "b) [Analysis by Income Category](#income_category) <br><br>\n",
    "\n",
    "IV. <b>Assesing Risks</b><br>\n",
    "a) [Understanding the Risky Side of Business](#risky_side)<br>\n",
    "b) [The importance of Credit Scores](#credit_scores)<br>\n",
    "c) [What determines a bad loan](#determines_bad_loan)<br>\n",
    "d) [Defaulted Loans](#defaulted_loans)\n",
    "e) [Risks by Purposes](#loan_condition)\n",
    "\n",
    "## References:\n",
    "1) <a src=\"https://www.kaggle.com/arthurtok/global-religion-1945-2010-plotly-pandas-visuals\"> Global Religion 1945-2010: Plotly & Pandas visuals</a> by Anisotropic <br>\n",
    "2) <a src=\"https://www.kaggle.com/vigilanf/loan-metrics-by-state\"> Loan Metrics By State </a> by Frank Vigilante<br>\n",
    "3) Hands on Machine Learning by Aurélien Géron <br>\n",
    "4) <a src=\"https://www.youtube.com/watch?v=oYbVFhK_olY&list=PLSPWNkAMSvv5DKeSVDbEbUKSsK4Z-GgiP\"> Deep Learning with Neural Networks and TensorFlow </a> by Sentdex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07ed872d-6dbb-4c7e-9244-7f565e0c7d38",
    "_uuid": "a7b75f3526a75485e089933ae775aec5555fe2ce"
   },
   "source": [
    "# Introduction:\n",
    "## General Information:\n",
    "<a id=\"general_information\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "428e7e85-93ed-45b1-aa24-cba4a771c2f3",
    "_uuid": "d65b7b14701cf9c42ec8cbb1ecfdfe6ab3358ae7"
   },
   "outputs": [],
   "source": [
    "# Import our libraries we are going to use for our data analysis.\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotly visualizations\n",
    "from plotly import tools\n",
    "import chart_studio.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# plotly.tools.set_credentials_file(username='AlexanderBach', api_key='o4fx6i1MtEIJQxfWYvU1')\n",
    "\n",
    "\n",
    "# For oversampling Library (Dealing with Imbalanced Datasets)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Other Libraries\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('../lending_club_loan_dataset2/accepted_2007_to_2018Q4.csv', low_memory=False)\n",
    "\n",
    "#Dropping last 30 row's with no values:\n",
    "df = df[df['fico_range_high'].notnull()]\n",
    "\n",
    "# Copy of the dataframe\n",
    "original_df = df.copy()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e81133a-2dbe-4126-8ad6-e1c84efa915f",
    "_kg_hide-input": true,
    "_uuid": "0ee2926e3668a0c3beb7b06ce9f14809c1e37053"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f054ecf3-735e-4ff8-a701-9210507e1cac",
    "_kg_hide-input": true,
    "_uuid": "0ff8dc19af3f2ad57e2c9c8c02a2047fb502bd1e"
   },
   "outputs": [],
   "source": [
    "# Replace the name of some columns\n",
    "df = df.rename(columns={\"loan_amnt\": \"loan_amount\", \"funded_amnt\": \"funded_amount\", \"funded_amnt_inv\": \"investor_funds\",\n",
    "                       \"int_rate\": \"interest_rate\", \"annual_inc\": \"annual_income\"})\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df.drop(['id', 'member_id', 'emp_title', 'url', 'desc', 'zip_code', 'title', 'sec_app_fico_range_low', 'sec_app_fico_range_high'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9390f158-796f-4f69-b145-b1d2a5584745",
    "_uuid": "ab357844a9985a3783a813423e08f5166830203b"
   },
   "source": [
    "## Similar Distributions:\n",
    "<a id=\"similar_distributions\"></a>\n",
    "We will start by exploring the distribution of the loan amounts and see when did the loan amount issued increased significantly. <br>\n",
    "\n",
    "<h4> What we need to know: </h4> <br>\n",
    "<ul>\n",
    "<li> Understand what amount was <b>mostly issued</b> to borrowers. </li>\n",
    "<li> Which <b>year</b> issued the most loans. </li>\n",
    "<li> The distribution of loan amounts is a <b>multinomial distribution </b>.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n",
    "<h4> Summary: </h4><br>\n",
    "<ul>\n",
    "<li> Most of the <b>loans issued</b> were in the range of 10,000 to 20,000 USD. </li>\n",
    "<li> The <b>year of 2015</b> was the year were most loans were issued.</li> \n",
    "<li> Loans were issued in an <b>incremental manner</b>. (Possible due to a recovery in the U.S economy) </li>\n",
    "<li> The loans <b>applied</b> by potential borrowers, the amount <b>issued</b> to the borrowers and the amount <b>funded</b> by investors are similarly distributed, <b>meaning</b> that it is most likely that qualified borrowers are going to get the loan they had applied for. </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe7b0217-b372-444e-9f6c-d1ed5fe5259c",
    "_kg_hide-input": true,
    "_uuid": "dca1e813e0820c7e422c4eadf66e2a71fda28b94"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16,5))\n",
    "\n",
    "\n",
    "df[\"loan_amount\"] = df[\"loan_amount\"].fillna(0)\n",
    "df[\"funded_amount\"] = df[\"funded_amount\"].fillna(0)\n",
    "df[\"investor_funds\"] = df[\"investor_funds\"].fillna(0)\n",
    "\n",
    "loan_amount = df[\"loan_amount\"].values\n",
    "funded_amount = df[\"funded_amount\"].values\n",
    "investor_funds = df[\"investor_funds\"].values\n",
    "\n",
    "\n",
    "sns.distplot(loan_amount, ax=ax[0], color=\"#F7522F\")\n",
    "ax[0].set_title(\"Loan Applied by the Borrower\", fontsize=14)\n",
    "sns.distplot(funded_amount, ax=ax[1], color=\"#2F8FF7\")\n",
    "ax[1].set_title(\"Amount Funded by the Lender\", fontsize=14)\n",
    "sns.distplot(investor_funds, ax=ax[2], color=\"#2EAD46\")\n",
    "ax[2].set_title(\"Total committed by Investors\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b0d59461-2e0f-44e7-bb9c-7dc57934b488",
    "_kg_hide-input": true,
    "_uuid": "de70a0eb750a61d68838339b3bf60f9136585c29"
   },
   "outputs": [],
   "source": [
    "# Lets' transform the issue dates by year.\n",
    "df['issue_d'].head()\n",
    "dt_series = pd.to_datetime(df['issue_d'])\n",
    "df['year'] = dt_series.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61bff410-2904-4f17-93e5-c724a778e019",
    "_kg_hide-input": true,
    "_uuid": "04a7f159ba7620fd10780e7ff9c1320f428f83b5"
   },
   "outputs": [],
   "source": [
    "# The year of 2015 was the year were the highest amount of loans were issued \n",
    "# This is an indication that the economy is quiet recovering itself.\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot('year', 'loan_amount', data=df, palette='Set2')\n",
    "plt.title('Issuance of Loans', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Average loan amount issued', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68557789-fb4c-43d9-a5c5-f588085aace7",
    "_uuid": "cc873fd882cba9ee89a01f64ce9b390fdc3b9f25"
   },
   "source": [
    "<h1 align=\"center\"> Good Loans vs Bad Loans: </h1>\n",
    "<h2>Types of Loans: </h2>\n",
    "<a id=\"types_of_loans\"></a>\n",
    "\n",
    "<br>\n",
    "In this section, we will see what is the amount of bad loans Lending Club has declared so far, of course we have to understand that there are still loans that are at a risk of defaulting in the future. \n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul>\n",
    "<li> The amount of bad loans could <b>increment</b> as the days pass by, since we still have a great amount of current loans. </li>\n",
    "<li> <b>Average annual income</b> is an important key metric for finding possible opportunities of investments in a specific region. </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li> Currently, <b>bad loans</b> consist 7.60% of total loans but remember that we still have <b>current loans</b> which have the risk of becoming bad loans. (So this percentage is subjected to possible changes.) </li>\n",
    "<li> The <b> NorthEast </b> region seems to be the most attractive in term of funding loans to borrowers. </li>\n",
    "<li> The <b> SouthWest </b> and <b> West</b> regions have experienced a slight increase in the \"median income\" in the past years. </li> \n",
    "<li> <b>Average interest</b> rates have declined since 2012 but this might explain the <b>increase in the volume</b> of loans.  </li>\n",
    "<li> <b>Employment Length</b> tends to be greater in the regions of the <b>SouthWest</b> and <b>West</b></li>\n",
    "<li> Clients located in the regions of <b>NorthEast</b> and <b>MidWest</b> have not experienced a drastic increase in debt-to-income(dti) as compared to the other regions. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85412154-d30d-4f7f-96b2-d41b6d94ab74",
    "_kg_hide-input": true,
    "_uuid": "f6cd906337ab70e068887b011bd29dd1e628b0f1"
   },
   "outputs": [],
   "source": [
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61d96d6a-f3f8-4a34-a4c8-3d77c4ebee31",
    "_kg_hide-input": true,
    "_uuid": "6fd3553700f3eb4889e88517d2b8e5b7d904872e"
   },
   "outputs": [],
   "source": [
    "# Determining the loans that are bad from loan_status column\n",
    "\n",
    "bad_loan = [\"Charged Off\", \"Default\", \"Does not meet the credit policy. Status:Charged Off\"]\n",
    "\n",
    "\n",
    "df['loan_condition'] = np.nan\n",
    "\n",
    "def loan_condition(status):\n",
    "    if status in bad_loan:\n",
    "        return 'Bad Loan'\n",
    "    else:\n",
    "        return 'Good Loan'\n",
    "    \n",
    "    \n",
    "df['loan_condition'] = df['loan_status'].apply(loan_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac878d77-5702-4daf-adfe-d61657043e90",
    "_kg_hide-input": true,
    "_uuid": "596bd11ee859fec86ca3a4469b6f98a7f13f4035",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "\n",
    "colors = [\"#3791D7\", \"#D72626\"]\n",
    "labels =\"Good Loans\", \"Bad Loans\"\n",
    "\n",
    "plt.suptitle('Information on Loan Conditions', fontsize=20)\n",
    "\n",
    "df[\"loan_condition\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n",
    "                                             labels=labels, fontsize=12, startangle=70)\n",
    "\n",
    "\n",
    "# ax[0].set_title('State of Loan', fontsize=16)\n",
    "ax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n",
    "\n",
    "# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n",
    "# ax[1].set_title('Condition of Loans', fontsize=20)\n",
    "# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\n",
    "palette = [\"#3791D7\", \"#E01E1B\"]\n",
    "\n",
    "sns.barplot(x=\"year\", y=\"loan_amount\", hue=\"loan_condition\", data=df, palette=palette, estimator=lambda x: len(x)/ len(df) * 100)\n",
    "ax[1].set(ylabel=\"(%) of Total Loan Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6871315f-0d27-4b08-8502-247fb711ec50",
    "_uuid": "cef68413efdb6b4f48b0c640bd0c5e877800ede1"
   },
   "source": [
    "<h2> Loans Issued by Region</h2>\n",
    "<a id=\"by_region\"></a>\n",
    "In this section we want to analyze loans issued by region in order to see region patters that will allow us to understand which region gives Lending Club.<br><br>\n",
    "\n",
    "## Summary: <br>\n",
    "<ul>\n",
    "<li> <b> SouthEast</b> , <b>West </b> and <b>NorthEast</b> regions had the highest amount lof loans issued. </li>\n",
    "<li> <b>West </b> and <b>SouthWest </b> had a rapid increase in debt-to-income starting in 2012. </li>\n",
    "<li><b>West </b> and <b>SouthWest </b>  had a rapid decrease in interest rates (This might explain the increase in debt to income). </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f82148c1-5a13-4af0-b7b3-c6fb767864ca",
    "_kg_hide-input": true,
    "_uuid": "3af220b72bb3bfd067086f3c2049b6e04da0808c"
   },
   "outputs": [],
   "source": [
    "df['addr_state'].unique()\n",
    "\n",
    "# Make a list with each of the regions by state.\n",
    "\n",
    "west = ['CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID']\n",
    "south_west = ['AZ', 'TX', 'NM', 'OK']\n",
    "south_east = ['GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN' ]\n",
    "mid_west = ['IL', 'MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND']\n",
    "north_east = ['CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME']\n",
    "\n",
    "\n",
    "\n",
    "df['region'] = np.nan\n",
    "\n",
    "def finding_regions(state):\n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    \n",
    "\n",
    "\n",
    "df['region'] = df['addr_state'].apply(finding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "74afbde0-508f-4bfb-92de-373c3f6dd0e2",
    "_kg_hide-input": true,
    "_uuid": "03f1590c7a754ccba10fd3a7051a587f4a4b98da"
   },
   "outputs": [],
   "source": [
    "# This code will take the current date and transform it into a year-month format\n",
    "df['complete_date'] = pd.to_datetime(df['issue_d'])\n",
    "\n",
    "group_dates = df.groupby(['complete_date', 'region'], as_index=False).sum()\n",
    "\n",
    "group_dates['issue_d'] = [month.to_period('M') for \n",
    "                          month in group_dates['complete_date']]\n",
    "\n",
    "group_dates = group_dates.groupby(['issue_d', 'region'], as_index=False).sum()\n",
    "group_dates = group_dates.groupby(['issue_d', 'region'], as_index=False).sum()\n",
    "group_dates['loan_amount'] = group_dates['loan_amount']/1000\n",
    "\n",
    "\n",
    "df_dates = pd.DataFrame(data=group_dates[['issue_d','region','loan_amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9de5aa56-be65-49bc-8c02-a12eca0f8aa0",
    "_kg_hide-input": true,
    "_uuid": "a1c7340953b00c99b113e915a39bfc6457fc4981"
   },
   "outputs": [],
   "source": [
    "#plt.style.use('light_background')\n",
    "cmap = plt.cm.Accent\n",
    "\n",
    "by_issued_amount = df_dates.groupby(['issue_d', 'region']).loan_amount.sum()\n",
    "by_issued_amount.unstack().plot(stacked=False, colormap=cmap, grid=False, legend=True, figsize=(15,6))\n",
    "\n",
    "plt.title('Loans issued by Region', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5fe5597b-abd4-4366-88b5-7c735692b0c2",
    "_kg_hide-input": true,
    "_uuid": "b26ef6d24ea7d2dc41fe2a2626694399e61b6141"
   },
   "outputs": [],
   "source": [
    "employment_length = ['10+ years', '< 1 year', '1 year', '3 years', '8 years', '9 years',\n",
    "                    '4 years', '5 years', '6 years', '2 years', '7 years', 'n/a']\n",
    "\n",
    "# Create a new column and convert emp_length to integers.\n",
    "\n",
    "lst = [df]\n",
    "df['emp_length_int'] = np.nan\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col['emp_length'] == '10+ years', \"emp_length_int\"] = 10\n",
    "    col.loc[col['emp_length'] == '9 years', \"emp_length_int\"] = 9\n",
    "    col.loc[col['emp_length'] == '8 years', \"emp_length_int\"] = 8\n",
    "    col.loc[col['emp_length'] == '7 years', \"emp_length_int\"] = 7\n",
    "    col.loc[col['emp_length'] == '6 years', \"emp_length_int\"] = 6\n",
    "    col.loc[col['emp_length'] == '5 years', \"emp_length_int\"] = 5\n",
    "    col.loc[col['emp_length'] == '4 years', \"emp_length_int\"] = 4\n",
    "    col.loc[col['emp_length'] == '3 years', \"emp_length_int\"] = 3\n",
    "    col.loc[col['emp_length'] == '2 years', \"emp_length_int\"] = 2\n",
    "    col.loc[col['emp_length'] == '1 year', \"emp_length_int\"] = 1\n",
    "    col.loc[col['emp_length'] == '< 1 year', \"emp_length_int\"] = 0.5\n",
    "    col.loc[col['emp_length'] == 'n/a', \"emp_length_int\"] = 0\n",
    "    \n",
    "    \n",
    "df.drop('emp_length', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c453a61-ce53-459b-bf38-d02a56d24b81",
    "_kg_hide-input": true,
    "_uuid": "fc10ef7575055551e8bce935b642c0fcceb93527"
   },
   "outputs": [],
   "source": [
    "# Loan issued by Region and by Credit Score grade\n",
    "# Change the colormap for tomorrow!\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "cmap = plt.cm.Spectral\n",
    "\n",
    "by_interest_rate = df.groupby(['year', 'region']).interest_rate.mean()\n",
    "by_interest_rate.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax1, figsize=(16,12))\n",
    "ax1.set_title('Average Interest Rate by Region', fontsize=14)\n",
    "\n",
    "\n",
    "by_employment_length = df.groupby(['year', 'region']).emp_length_int.mean()\n",
    "by_employment_length.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax2, figsize=(16,12))\n",
    "ax2.set_title('Average Employment Length by Region', fontsize=14)\n",
    "# plt.xlabel('Year of Issuance', fontsize=14)\n",
    "\n",
    "by_dti = df.groupby(['year', 'region']).dti.mean()\n",
    "by_dti.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, legend=False, ax=ax3, figsize=(16,12))\n",
    "ax3.set_title('Average Debt-to-Income by Region', fontsize=14)\n",
    "\n",
    "by_income = df.groupby(['year', 'region']).annual_income.mean()\n",
    "by_income.unstack().plot(kind='area', stacked=True, colormap=cmap, grid=False, ax=ax4, figsize=(16,12))\n",
    "ax4.set_title('Average Annual Income by Region', fontsize=14)\n",
    "ax4.legend(bbox_to_anchor=(-1.0, -0.5, 1.8, 0.1), loc=10,prop={'size':12},\n",
    "           ncol=5, mode=\"expand\", borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec3c1e24-70e6-45bb-97ea-4c42ff69f84d",
    "_uuid": "234064b3f172cd733f7f416149b663b37ab4268b"
   },
   "source": [
    "## A Deeper Look into Bad Loans:\n",
    "<a id=\"deeper_bad_loans\"></a>\n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul> \n",
    "<li>The number of loans that were classified as bad loans for each region by its <b>loan status</b>. (This will be shown in a dataframe below.)</li>\n",
    "<li> This won't give us the exact reasons why a loan is categorized as a bad loan (other variables that might have influence the condition of the loan) but it will give us a <b> deeper insight on the level of risk </b> in a particular region. </li>\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li>The regions of the <b> West </b> and <b> SouthEast </b> had a higher percentage in most of the b \"bad\" loan statuses.</li>\n",
    "<li> The <b>NorthEast</b> region had a higher percentage in <b>Grace Period</b> and <b>Does not meet Credit Policy</b> loan status. However, both of these are not considered as bad as <b>default</b> for instance. </li>\n",
    "<li> Based on this small and brief summary we can conclude that the <b>West</b> and <b>SouthEast</b> regions have the most undesirable loan status, but just by a slightly higher percentage compared to the <b>NorthEast</b> region. </li>\n",
    "<li> Again, this does not tell us what causes a loan to be a <b> bad loan </b>, but it gives us some idea about <b>the level of risk</b> within the regions across the United States. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ec04af3-a602-4547-982d-f42dd15b2914",
    "_kg_hide-input": true,
    "_uuid": "b72bf3be29058e6f859939ea2f81a0f226a931e4"
   },
   "outputs": [],
   "source": [
    "# We have 67429 loans categorized as bad loans\n",
    "badloans_df = df.loc[df[\"loan_condition\"] == \"Bad Loan\"]\n",
    "\n",
    "# loan_status cross\n",
    "loan_status_cross = pd.crosstab(badloans_df['region'], badloans_df['loan_status']).apply(lambda x: x/x.sum() * 100)\n",
    "number_of_loanstatus = pd.crosstab(badloans_df['region'], badloans_df['loan_status'])\n",
    "\n",
    "\n",
    "# Round our values\n",
    "loan_status_cross['Charged Off'] = loan_status_cross['Charged Off'].apply(lambda x: round(x, 2))\n",
    "loan_status_cross['Default'] = loan_status_cross['Default'].apply(lambda x: round(x, 2))\n",
    "loan_status_cross['Does not meet the credit policy. Status:Charged Off'] = loan_status_cross['Does not meet the credit policy. Status:Charged Off'].apply(lambda x: round(x, 2))\n",
    "#loan_status_cross['In Grace Period'] = loan_status_cross['In Grace Period'].apply(lambda x: round(x, 2))\n",
    "#loan_status_cross['Late (16-30 days)'] = loan_status_cross['Late (16-30 days)'].apply(lambda x: round(x, 2))\n",
    "#loan_status_cross['Late (31-120 days)'] = loan_status_cross['Late (31-120 days)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "\n",
    "number_of_loanstatus['Total'] = number_of_loanstatus.sum(axis=1) \n",
    "# number_of_badloans\n",
    "number_of_loanstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2924ac56-0368-45e1-8474-3d3ffb78651c",
    "_kg_hide-input": true,
    "_uuid": "f18e32fe594a649502c501c296dc0ea75bd709d3"
   },
   "outputs": [],
   "source": [
    "charged_off = loan_status_cross['Charged Off'].values.tolist()\n",
    "default = loan_status_cross['Default'].values.tolist()\n",
    "not_meet_credit = loan_status_cross['Does not meet the credit policy. Status:Charged Off'].values.tolist()\n",
    "#grace_period = loan_status_cross['In Grace Period'].values.tolist()\n",
    "#short_pay = loan_status_cross['Late (16-30 days)'] .values.tolist()\n",
    "#long_pay = loan_status_cross['Late (31-120 days)'].values.tolist()\n",
    "\n",
    "\n",
    "\n",
    "charged = go.Bar(\n",
    "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "    y= charged_off,\n",
    "    name='Charged Off',\n",
    "    marker=dict(\n",
    "        color='turquoise'\n",
    "    ),\n",
    "    text = '%'\n",
    ")\n",
    "\n",
    "defaults = go.Bar(\n",
    "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "    y=default,\n",
    "    name='Defaults',\n",
    "    marker=dict(\n",
    "        color='yellowgreen'\n",
    "    ),\n",
    "    text = '%'\n",
    ")\n",
    "\n",
    "credit_policy = go.Bar(\n",
    "    x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "    y= not_meet_credit,\n",
    "    name='Does not meet Credit Policy',\n",
    "    marker = dict(\n",
    "        color='lightblue'\n",
    "    ),\n",
    "    text = '%'\n",
    ")\n",
    "\n",
    "# grace = go.Bar(\n",
    "#     x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "#     y= grace_period,\n",
    "#     name='Grace Period',\n",
    "#     marker = dict(\n",
    "#         color='rgb(147, 147, 147)'\n",
    "#     ),\n",
    "#     text = '%'\n",
    "# )\n",
    "\n",
    "# short_pays = go.Bar(\n",
    "#     x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "#     y= short_pay,\n",
    "#     name='Late Payment (16-30 days)', \n",
    "#     marker = dict(\n",
    "#         color='rgb(246, 157, 135)'\n",
    "#     ),\n",
    "#     text = '%'\n",
    "# )\n",
    "\n",
    "# long_pays = go.Bar(\n",
    "#     x=['MidWest', 'NorthEast', 'SouthEast', 'SouthWest', 'West'],\n",
    "#     y= long_pay,\n",
    "#     name='Late Payment (31-120 days)',\n",
    "#     marker = dict(\n",
    "#         color = 'rgb(238, 76, 73)'\n",
    "#         ),\n",
    "#     text = '%'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [charged, defaults, credit_policy]#, grace, short_pays, long_pays]\n",
    "layout = go.Layout(\n",
    "    barmode='stack',\n",
    "    title = '% of Bad Loan Status by Region',\n",
    "    xaxis=dict(title='US Regions')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='stacked-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5da6bde7-19fb-475c-a594-125288851fb5",
    "_kg_hide-input": true,
    "_uuid": "66fe044e83e0695eda2817ee8e02e8ed6e03fccb"
   },
   "outputs": [],
   "source": [
    "# Average interest rates clients pay\n",
    "print(df['interest_rate'].mean())\n",
    "# Average annual income of clients\n",
    "print(df['annual_income'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22cce5bc-2b49-4c3a-9966-3d9b0e07c250",
    "_uuid": "138a17bf8f796d021221755065c174401cdff6c2"
   },
   "source": [
    "<h1 align=\"center\"> The Business Perspective </h1>\n",
    "<h2 > Understanding the Operative Side of Business </h2>\n",
    "<a id=\"operative_side\"></a>\n",
    "<img src=\"http://bestcredit.sg/wp-content/uploads/2017/07/licensed-money-lender.jpg\"><br><br>\n",
    "Now we will have a closer look at the <b> operative side </b> of business by state. This will give us a clearer idea in which state we have a higher operating activity. This will allow us to ask further questions such as Why do we have a higher level of operating activity in this state? Could it be because of economic factors? or the risk level is low and returns are fairly decent? Let's explore!\n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul>\n",
    "<li> We will focus on <b>three key metrics</b>: Loans issued by state (Total Sum), Average interest rates charged to customers and average annual income of all customers by state. </li>\n",
    "<li> The purpose of this analysis is to see states that give high returns at a descent risk. </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li> <b>California, Texas, New York and Florida</b> are the states in which the highest amount of loans were issued. </li>\n",
    "<li> Interesting enough, all four states have a approximate <b>interest rate of 13%</b> which is at the same level of the average interest rate for all states (13.24%) </li>\n",
    "<li> California, Texas and New York are <b>all above the average annual income</b> (with the exclusion of Florida), this might give possible indication why most loans are issued in these states. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "23bcd908-a7fe-455e-a658-59b6fd9b7d64",
    "_kg_hide-input": true,
    "_uuid": "2d6663f515fcb697b6b0bc4bf138734e3d6beae9"
   },
   "outputs": [],
   "source": [
    "# Plotting by states\n",
    "\n",
    "# Grouping by our metrics\n",
    "# First Plotly Graph (We evaluate the operative side of the business)\n",
    "by_loan_amount = df.groupby(['region','addr_state'], as_index=False).loan_amount.sum()\n",
    "by_interest_rate = df.groupby(['region', 'addr_state'], as_index=False).interest_rate.mean()\n",
    "by_income = df.groupby(['region', 'addr_state'], as_index=False).annual_income.mean()\n",
    "\n",
    "\n",
    "\n",
    "# Take the values to a list for visualization purposes.\n",
    "states = by_loan_amount['addr_state'].values.tolist()\n",
    "average_loan_amounts = by_loan_amount['loan_amount'].values.tolist()\n",
    "average_interest_rates = by_interest_rate['interest_rate'].values.tolist()\n",
    "average_annual_income = by_income['annual_income'].values.tolist()\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Figure Number 1 (Perspective for the Business Operations)\n",
    "metrics_data = OrderedDict([('state_codes', states),\n",
    "                            ('issued_loans', average_loan_amounts),\n",
    "                            ('interest_rate', average_interest_rates),\n",
    "                            ('annual_income', average_annual_income)])\n",
    "                     \n",
    "\n",
    "metrics_df = pd.DataFrame.from_dict(metrics_data)\n",
    "metrics_df = metrics_df.round(decimals=2)\n",
    "metrics_df.head()\n",
    "\n",
    "\n",
    "\n",
    "# Think of a way to add default rate\n",
    "# Consider adding a few more metrics for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9658d3df-f822-4d89-ae55-cb1e2559507b",
    "_kg_hide-input": true,
    "_uuid": "d034ebaaa95dd36353bb96665bcca7117a56a7c5"
   },
   "outputs": [],
   "source": [
    "# Now it comes the part where we plot out plotly United States map\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "for col in metrics_df.columns:\n",
    "    metrics_df[col] = metrics_df[col].astype(str)\n",
    "    \n",
    "scl = [[0.0, 'rgb(210, 241, 198)'],[0.2, 'rgb(188, 236, 169)'],[0.4, 'rgb(171, 235, 145)'],\\\n",
    "            [0.6, 'rgb(140, 227, 105)'],[0.8, 'rgb(105, 201, 67)'],[1.0, 'rgb(59, 159, 19)']]\n",
    "\n",
    "metrics_df['text'] = metrics_df['state_codes'] + '<br>' +\\\n",
    "'Average loan interest rate: ' + metrics_df['interest_rate'] + '<br>'+\\\n",
    "'Average annual income: ' + metrics_df['annual_income'] \n",
    "\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = metrics_df['state_codes'],\n",
    "        z = metrics_df['issued_loans'], \n",
    "        locationmode = 'USA-states',\n",
    "        text = metrics_df['text'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"$s USD\")\n",
    "        ) ]\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Lending Clubs Issued Loans <br> (A Perspective for the Business Operations)',\n",
    "    geo = dict(\n",
    "        scope = 'usa',\n",
    "        projection=dict(type='albers usa'),\n",
    "        showlakes = True,\n",
    "        lakecolor = 'rgb(255, 255, 255)')\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "70d317a6-1c8f-497e-95b0-484931a6505e",
    "_uuid": "afa20ec1ac2f9c7170e0bf5def350833db1526ff"
   },
   "source": [
    "## Analysis by Income Category:\n",
    "<a id=\"income_category\"></a>\n",
    "In this section we will create different <b> income categories </b> in order to detect important patters and go more into depth in our analysis.\n",
    "\n",
    "**What we need to know:** <br>\n",
    "<ul>\n",
    "<li><b>Low income category:</b> Borrowers that have an annual income lower or equal to 100,000 usd.</li>\n",
    "<li> <b> Medium income category:</b> Borrowers that have an annual income higher than 100,000 usd but lower or equal to 200,000 usd. </li>\n",
    "<li><b> High income category: </b> Borrowers that have an annual income higher tha 200,000 usd. </li>\n",
    "</ul>\n",
    "\n",
    "**Summary:**\n",
    "<ul>\n",
    "<li>Borrowers that made part of the <b>high income category</b> took higher loan amounts than people from <b>low</b> and <b>medium income categories.</b> Of course, people with higher annual incomes are more likely to pay loans with a higher amount. (First row to the left of the subplots) </li>\n",
    "<li> Loans that were borrowed by the <b>Low income category</b> had a slightly higher change of becoming a bad loan. (First row to the right of the subplots) </li>\n",
    "<li>Borrowers with <b>High</b> and <b> Medium</b> annual incomes had a longer employment length than people with lower incomes.(Second row to the left of the subplots) </li>\n",
    "<li> Borrowers with a lower income had on average <b>higher interest rates</b> while people with a higher annual income had <b>lower interest rates</b> on their loans. (Second row to the right of the subplots)</li> \n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9703d5e9-d59b-4ed3-8a7c-ffb2eb118482",
    "_kg_hide-input": true,
    "_uuid": "91adcc85d6847933a074c9687c16755d1cb2b4d5"
   },
   "outputs": [],
   "source": [
    "# Let's create categories for annual_income since most of the bad loans are located below 100k\n",
    "\n",
    "df['income_category'] = np.nan\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col['annual_income'] <= 100000, 'income_category'] = 'Low'\n",
    "    col.loc[(col['annual_income'] > 100000) & (col['annual_income'] <= 200000), 'income_category'] = 'Medium'\n",
    "    col.loc[col['annual_income'] > 200000, 'income_category'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "697206b1-4a51-4b71-816c-f683e1e1e1b3",
    "_kg_hide-input": true,
    "_uuid": "306437009da2006a4253e97bdd09b8b6f3f5b2d1"
   },
   "outputs": [],
   "source": [
    "# Let's transform the column loan_condition into integers.\n",
    "\n",
    "lst = [df]\n",
    "df['loan_condition_int'] = np.nan\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[df['loan_condition'] == 'Good Loan', 'loan_condition_int'] = 0 # Negative (Bad Loan)\n",
    "    col.loc[df['loan_condition'] == 'Bad Loan', 'loan_condition_int'] = 1 # Positive (Good Loan)\n",
    "    \n",
    "# Convert from float to int the column (This is our label)  \n",
    "df['loan_condition_int'] = df['loan_condition_int'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba55fd70-e3aa-4e97-869e-d4af2928f0b1",
    "_uuid": "69859cabf2fb48c3f6efb3e1256035bf3f57f270"
   },
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4))= plt.subplots(nrows=2, ncols=2, figsize=(14,6))\n",
    "\n",
    "# Change the Palette types tomorrow!\n",
    "\n",
    "sns.violinplot(x=\"income_category\", y=\"loan_amount\", data=df, palette=\"YlGnBu\", ax=ax1 )\n",
    "sns.violinplot(x=\"income_category\", y=\"loan_condition_int\", data=df, palette=\"YlGnBu\", ax=ax2)\n",
    "sns.boxplot(x=\"income_category\", y=\"emp_length_int\", data=df, palette=\"YlGnBu\", ax=ax3)\n",
    "sns.boxplot(x=\"income_category\", y=\"interest_rate\", data=df, palette=\"YlGnBu\", ax=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5762c82-4b5c-457e-9295-f7732c21d38c",
    "_uuid": "9f4ca83a49dd49ba2cdef23a6f98ef02ca413c12"
   },
   "source": [
    "<h1 align=\"center\"> Assesing Risks </h1>\n",
    "<h2> Understanding the Risky side of Business </h2>\n",
    "<a id=\"risky_side\"></a>\n",
    "\n",
    "Although the <b> operative side of business </b> is important, we have to also analyze the level of risk in each state. Credit scores are important metrics to analyze the level of risk of an individual customer. However, there are also other important metrics to somehow estimate the level of risk of other states. <br><br>\n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul>\n",
    "<li> <b>Debt-to-income</b> is an important metric since it says approximately the level of debt of each individual consumer with respect to its total income. </li>\n",
    "<li> The <b>average length of employment</b> tells us a better story about the labor market in each state which is helpful to assess the levelof risk. </li>\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li> <b>IOWA</b> has the highest level of default ratio neverthless, the amount of loans issued in that state is <b>too low</b>. (Number of Bad loans is equal to 3) </li>\n",
    "<li> California and Texas seem to have the lowest risk and the highest possible return for investors. However, I will look more deeply into these states and create other metrics analyze the level of risk for each state. </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "\n",
    "**Note: I will be updating these section sooner or later (Stay in touch!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "43d99fa7-4658-4463-bb49-74ed4d0e1063",
    "_kg_hide-input": true,
    "_uuid": "222fe26e9f614a715da22bcdd1f10746d76d35a2"
   },
   "outputs": [],
   "source": [
    "by_condition = df.groupby('addr_state')['loan_condition'].value_counts()/ df.groupby('addr_state')['loan_condition'].count()\n",
    "by_emp_length = df.groupby(['region', 'addr_state'], as_index=False).emp_length_int.mean().sort_values(by=\"addr_state\")\n",
    "\n",
    "loan_condition_bystate = pd.crosstab(df['addr_state'], df['loan_condition'] )\n",
    "\n",
    "cross_condition = pd.crosstab(df[\"addr_state\"], df[\"loan_condition\"])\n",
    "# Percentage of condition of loan\n",
    "percentage_loan_contributor = pd.crosstab(df['addr_state'], df['loan_condition']).apply(lambda x: x/x.sum() * 100)\n",
    "condition_ratio = cross_condition[\"Bad Loan\"]/cross_condition[\"Good Loan\"]\n",
    "by_dti = df.groupby(['region', 'addr_state'], as_index=False).dti.mean()\n",
    "state_codes = sorted(states)\n",
    "\n",
    "\n",
    "# Take to a list\n",
    "default_ratio = condition_ratio.values.tolist()\n",
    "average_dti = by_dti['dti'].values.tolist()\n",
    "average_emp_length = by_emp_length[\"emp_length_int\"].values.tolist()\n",
    "number_of_badloans = loan_condition_bystate['Bad Loan'].values.tolist()\n",
    "percentage_ofall_badloans = percentage_loan_contributor['Bad Loan'].values.tolist()\n",
    "\n",
    "\n",
    "# Figure Number 2\n",
    "risk_data = OrderedDict([('state_codes', state_codes),\n",
    "                         ('default_ratio', default_ratio),\n",
    "                         ('badloans_amount', number_of_badloans),\n",
    "                         ('percentage_of_badloans', percentage_ofall_badloans),\n",
    "                         ('average_dti', average_dti),\n",
    "                         ('average_emp_length', average_emp_length)])\n",
    "\n",
    "\n",
    "# Figure 2 Dataframe \n",
    "risk_df = pd.DataFrame.from_dict(risk_data)\n",
    "risk_df = risk_df.round(decimals=3)\n",
    "risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39a3e3fb-c123-4258-8d56-99f48954c4df",
    "_kg_hide-input": true,
    "_uuid": "2e1e336a86a51b03a20f29776c994b03e4cf5a63"
   },
   "outputs": [],
   "source": [
    "# Now it comes the part where we plot out plotly United States map\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "for col in risk_df.columns:\n",
    "    risk_df[col] = risk_df[col].astype(str)\n",
    "    \n",
    "scl = [[0.0, 'rgb(202, 202, 202)'],[0.2, 'rgb(253, 205, 200)'],[0.4, 'rgb(252, 169, 161)'],\\\n",
    "            [0.6, 'rgb(247, 121, 108  )'],[0.8, 'rgb(232, 70, 54)'],[1.0, 'rgb(212, 31, 13)']]\n",
    "\n",
    "risk_df['text'] = risk_df['state_codes'] + '<br>' +\\\n",
    "'Number of Bad Loans: ' + risk_df['badloans_amount'] + '<br>' + \\\n",
    "'Percentage of all Bad Loans: ' + risk_df['percentage_of_badloans'] + '%' +  '<br>' + \\\n",
    "'Average Debt-to-Income Ratio: ' + risk_df['average_dti'] + '<br>'+\\\n",
    "'Average Length of Employment: ' + risk_df['average_emp_length'] \n",
    "\n",
    "\n",
    "data = [ dict(\n",
    "        type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = risk_df['state_codes'],\n",
    "        z = risk_df['default_ratio'], \n",
    "        locationmode = 'USA-states',\n",
    "        text = risk_df['text'],\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"%\")\n",
    "        ) ]\n",
    "\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Lending Clubs Default Rates <br> (Analyzing Risks)',\n",
    "    geo = dict(\n",
    "        scope = 'usa',\n",
    "        projection=dict(type='albers usa'),\n",
    "        showlakes = True,\n",
    "        lakecolor = 'rgb(255, 255, 255)')\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cbe5e3e3-289c-45f8-9cb9-e5792363fd53",
    "_uuid": "be1fa255c95aabede8da476fdfedd40da5b3b4a6"
   },
   "source": [
    "## The Importance of Credit Scores:\n",
    "<a id=\"credit_scores\"></a>\n",
    "Credit scores are important metrics for assesing the overall level of risk. In this section we will analyze the level of risk as a whole and how many loans were bad loans by the type of grade received in the credit score of the customer.\n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul> \n",
    "<li> The lower the grade of the credit score, the higher the risk for investors. </li>\n",
    "<li> There are different factors that influence on the level of risk of the loan.</li>\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li> The scores that has a lower grade received a larger amounts of loans (which might had contributed to a higher level of risk). </li>\n",
    "<li> Logically, the <b>lower the grade the higher the interest</b> the customer had to pay back to investors.</li>\n",
    "<li> Interstingly, customers with a <b>grade</b> of \"C\" were more likely to default on the loan </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72c471f0-91a8-4e19-bd7c-16704f30501c",
    "_kg_hide-input": true,
    "_uuid": "0a0df1473572f180ac8a4c94b9fca66ed80634f6"
   },
   "outputs": [],
   "source": [
    "# Let's visualize how many loans were issued by creditscore\n",
    "f, ((ax1, ax2)) = plt.subplots(1, 2)\n",
    "cmap = plt.cm.coolwarm\n",
    "\n",
    "by_credit_score = df.groupby(['year', 'grade']).loan_amount.mean()\n",
    "by_credit_score.unstack().plot(legend=False, ax=ax1, figsize=(14, 4), colormap=cmap)\n",
    "ax1.set_title('Loans issued by Credit Score', fontsize=14)\n",
    "    \n",
    "    \n",
    "by_inc = df.groupby(['year', 'grade']).interest_rate.mean()\n",
    "by_inc.unstack().plot(ax=ax2, figsize=(14, 4), colormap=cmap)\n",
    "ax2.set_title('Interest Rates by Credit Score', fontsize=14)\n",
    "\n",
    "ax2.legend(bbox_to_anchor=(-1.0, -0.3, 1.7, 0.1), loc=5, prop={'size':12},\n",
    "           ncol=7, mode=\"expand\", borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba20dded-74a0-48de-bc66-1530abdd7cb2",
    "_kg_hide-input": true,
    "_uuid": "d9d859fd942b7ed538a680a2fbe0cc05c997cc50"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,12))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(212)\n",
    "\n",
    "cmap = plt.cm.coolwarm_r\n",
    "\n",
    "loans_by_region = df.groupby(['grade', 'loan_condition']).size()\n",
    "loans_by_region.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax1, grid=False)\n",
    "ax1.set_title('Type of Loans by Grade', fontsize=14)\n",
    "\n",
    "\n",
    "loans_by_grade = df.groupby(['sub_grade', 'loan_condition']).size()\n",
    "loans_by_grade.unstack().plot(kind='bar', stacked=True, colormap=cmap, ax=ax2, grid=False)\n",
    "ax2.set_title('Type of Loans by Sub-Grade', fontsize=14)\n",
    "\n",
    "by_interest = df.groupby(['year', 'loan_condition']).interest_rate.mean()\n",
    "by_interest.unstack().plot(ax=ax3, colormap=cmap)\n",
    "ax3.set_title('Average Interest rate by Loan Condition', fontsize=14)\n",
    "ax3.set_ylabel('Interest Rate (%)', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "265914e0-b326-4b6c-8cad-a55ebce491b7",
    "_uuid": "5a63504f01a6e3e7088f57138754724e166b4d7e"
   },
   "source": [
    "<h2>What Determines a Bad Loan </h2>\n",
    "<a id=\"determines_bad_loan\"></a>\n",
    "My main aim in this section is to find the main factors that causes for a loan to be considered a <b>\"Bad Loan\"</b>. Logically, we could assume that factors such as a low credit grade or a high debt to income could be possible contributors in determining whether a loan is at a high risk of being defaulted. <br><br>\n",
    "\n",
    "<h4> What we need to know: </h4>\n",
    "<ul>\n",
    "<li> There might be possible factors that contribute in whether a loan is bad or not. </li>\n",
    "<li> Factors that increase risk include: low annual income, high debt to income, high interest rates, low grade, among others. </li>\n",
    "</ul>\n",
    "\n",
    "<h4> Summary: </h4>\n",
    "<ul>\n",
    "<li> The types of bad loans in the last year are having a tendency to<b> decline</b>, except for late payments (might indicate an economical recovery.) </li>\n",
    "<li> <b>Mortgage </b> was the variable from the home ownership column that used the highest amount borrowed within loans that were considered to be bad.</li>\n",
    "<li> There is a slight <b>increase</b> on people who have mortgages that are applying for a loan.</li>\n",
    "<li>People who have a mortgage (depending on other factors as well within the mortgage) are more likely to ask for <bhigher loan amounts than other people who have other types of home ownerships. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "19a36a8e-0863-45a2-9d31-5e71a038aff5",
    "_uuid": "ce76bb007c77bf64c91ef010f11c8f5a49aa8817"
   },
   "outputs": [],
   "source": [
    "# Just get me the numeric variables\n",
    "numeric_variables = df.select_dtypes(exclude=[\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8084478f-0d2d-4922-87a3-f6fd002465da",
    "_kg_hide-input": true,
    "_uuid": "562f902591f808328462b310066571f8e2f0a0e5"
   },
   "outputs": [],
   "source": [
    "# We will use df_correlations dataframe to analyze our correlations.\n",
    "\n",
    "\n",
    "df_correlations = df.corr()\n",
    "\n",
    "\n",
    "trace = go.Heatmap(z=df_correlations.values,\n",
    "                   x=df_correlations.columns,\n",
    "                   y=df_correlations.columns,\n",
    "                  colorscale=[[0.0, 'rgb(165,0,38)'], \n",
    "                              [0.1111111111111111, 'rgb(215,48,39)'], \n",
    "                              [0.2222222222222222, 'rgb(244,109,67)'], \n",
    "                              [0.3333333333333333, 'rgb(253,174,97)'], \n",
    "                              [0.4444444444444444, 'rgb(254,224,144)'], \n",
    "                              [0.5555555555555556, 'rgb(224,243,248)'], \n",
    "                              [0.6666666666666666, 'rgb(171,217,233)'], \n",
    "                              [0.7777777777777778, 'rgb(116,173,209)'], \n",
    "                              [0.8888888888888888, 'rgb(69,117,180)'], \n",
    "                              [1.0, 'rgb(49,54,149)']],\n",
    "            colorbar = dict(\n",
    "            title = 'Level of Correlation',\n",
    "            titleside = 'top',\n",
    "            tickmode = 'array',\n",
    "            tickvals = [-0.52,0.2,0.95],\n",
    "            ticktext = ['Negative Correlation','Low Correlation','Positive Correlation'],\n",
    "            ticks = 'outside'\n",
    "        )\n",
    "                  )\n",
    "\n",
    "\n",
    "layout = {\"title\": \"Correlation Heatmap\"}\n",
    "data=[trace]\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d778b66-27da-4933-8b30-1106056e8111",
    "_uuid": "bad06adcb774d5515d7fe653a247d9aa7f5a71e1"
   },
   "source": [
    "This data looks a little but messy maybe if we focus our correlation heatmap into columns that are more worth it we might actually see a trend with the **condition of the loan**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ac9ade7-50ca-413b-a3a4-f0024c2a7005",
    "_kg_hide-input": true,
    "_uuid": "93234728cf730963285429c2ae2a4a610e0c5588"
   },
   "outputs": [],
   "source": [
    "title = 'Bad Loans: Loan Statuses'\n",
    "\n",
    "labels = bad_loan # All the elements that comprise a bad loan.\n",
    "\n",
    "len(labels)\n",
    "colors = ['rgba(236, 112, 99, 1)', 'rgba(235, 152, 78, 1)', 'rgba(52, 73, 94, 1)', 'rgba(128, 139, 150, 1)',\n",
    "         'rgba(255, 87, 51, 1)', 'rgba(255, 195, 0, 1)']\n",
    "\n",
    "mode_size = [8,8,8,8,8,8]\n",
    "\n",
    "line_size = [2,2,2,2,2,2]\n",
    "\n",
    "x_data = [\n",
    "    sorted(df['year'].unique().tolist()),\n",
    "    sorted(df['year'].unique().tolist()),\n",
    "    sorted(df['year'].unique().tolist()),\n",
    "    sorted(df['year'].unique().tolist()), \n",
    "    sorted(df['year'].unique().tolist()),\n",
    "    sorted(df['year'].unique().tolist()),\n",
    "]\n",
    "\n",
    "# type of loans\n",
    "charged_off = df['loan_amount'].loc[df['loan_status'] == 'Charged Off'].values.tolist()\n",
    "defaults = df['loan_amount'].loc[df['loan_status'] == 'Default'].values.tolist()\n",
    "not_credit_policy = df['loan_amount'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'].values.tolist()\n",
    "# grace_period = df['loan_amount'].loc[df['loan_status'] == 'In Grace Period'].values.tolist()\n",
    "# short_late = df['loan_amount'].loc[df['loan_status'] == 'Late (16-30 days)'].values.tolist()\n",
    "# long_late = df['loan_amount'].loc[df['loan_status'] == 'Late (31-120 days)'].values.tolist()\n",
    "\n",
    "y_data = [\n",
    "    charged_off,\n",
    "    defaults,\n",
    "    not_credit_policy,\n",
    "#    grace_period,\n",
    "#     short_late,\n",
    "#     long_late,\n",
    "]\n",
    "\n",
    "p_charged_off = go.Scatter(\n",
    "    x = x_data[0],\n",
    "    y = y_data[0],\n",
    "    name = 'A. Charged Off',\n",
    "    line = dict(\n",
    "        color = colors[0],\n",
    "        width = 3,\n",
    "        dash='dash')\n",
    ")\n",
    "\n",
    "p_defaults = go.Scatter(\n",
    "    x = x_data[1],\n",
    "    y = y_data[1],\n",
    "    name = 'A. Defaults',\n",
    "    line = dict(\n",
    "        color = colors[1],\n",
    "        width = 3,\n",
    "        dash='dash')\n",
    ")\n",
    "\n",
    "p_credit_policy = go.Scatter(\n",
    "    x = x_data[2],\n",
    "    y = y_data[2],\n",
    "    name = 'Not Meet C.P',\n",
    "    line = dict(\n",
    "        color = colors[2],\n",
    "        width = 3,\n",
    "        dash='dash')\n",
    ")\n",
    "\n",
    "# p_graced = go.Scatter(\n",
    "#     x = x_data[3],\n",
    "#     y = y_data[3],\n",
    "#     name = 'A. Graced Period',\n",
    "#     line = dict(\n",
    "#         color = colors[3],\n",
    "#         width = 3,\n",
    "#         dash='dash')\n",
    "# )\n",
    "\n",
    "# p_short_late = go.Scatter(\n",
    "#     x = x_data[4],\n",
    "#     y = y_data[4],\n",
    "#     name = 'Late (16-30 days)',\n",
    "#     line = dict(\n",
    "#         color = colors[4],\n",
    "#         width = 3,\n",
    "#         dash='dash')\n",
    "# )\n",
    "\n",
    "# p_long_late = go.Scatter(\n",
    "#     x = x_data[5],\n",
    "#     y = y_data[5],\n",
    "#     name = 'Late (31-120 days)',\n",
    "#     line = dict(\n",
    "#         color = colors[5],\n",
    "#         width = 3,\n",
    "#         dash='dash')\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data=[p_charged_off, p_defaults, p_credit_policy]#, p_graced, p_short_late, p_long_late]\n",
    "\n",
    "layout = dict(title = 'Types of Bad Loans <br> (Amount Borrowed Throughout the Years)',\n",
    "              xaxis = dict(title = 'Year'),\n",
    "              yaxis = dict(title = 'Amount Issued'),\n",
    "              )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fa9e904b-b8be-4e54-b260-415497101239",
    "_kg_hide-input": true,
    "_uuid": "9f4988abfc9615bf59f35044c3b03aa75ab21126"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "\n",
    "# Create a dataframe for bad loans\n",
    "bad_df = df.loc[df['loan_condition'] == 'Bad Loan']\n",
    "\n",
    "plt.subplot(211)\n",
    "g = sns.boxplot(x='home_ownership', y='loan_amount', hue='loan_condition',\n",
    "               data=bad_df, color='r')\n",
    "\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_xlabel(\"Type of Home Ownership\", fontsize=12)\n",
    "g.set_ylabel(\"Loan Amount\", fontsize=12)\n",
    "g.set_title(\"Distribution of Amount Borrowed \\n by Home Ownership\", fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "g1 = sns.boxplot(x='year', y='loan_amount', hue='home_ownership',\n",
    "               data=bad_df, palette=\"Set2\")\n",
    "g1.set_xticklabels(g1.get_xticklabels(),rotation=45)\n",
    "g1.set_xlabel(\"Type of Home Ownership\", fontsize=12)\n",
    "g1.set_ylabel(\"Loan Amount\", fontsize=12)\n",
    "g1.set_title(\"Distribution of Amount Borrowed \\n through the years\", fontsize=16)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9cbebcdb-0445-44dd-960c-c4dbc734929c",
    "_uuid": "fa94049d344e0cd0407274ff094fd28302b4cd73"
   },
   "source": [
    "## Defaulted Loans and Level of Risk:\n",
    "<a id=\"defaulted_loans\"></a>\n",
    "From all the bad loans the one we are most interested about are the loans that are defaulted. Therefore, in this section we will implement an in-depth analysis of these types of Loans and see if we can gain any insight as to which features have a high correlation with the loan being defaulted.\n",
    "\n",
    "## Main Aim:\n",
    "<ul>\n",
    "<li> Determine patters that will allow us to understand somehow factors that contribute to a loan being <b>defaulted</b> </li>\n",
    "</ul>\n",
    "\n",
    "## Summary:\n",
    "<ul>\n",
    "<li>In the last year recorded, the <b>Midwest </b>  and <b> SouthEast </b> regions had the most defaults. </li>\n",
    "<li>Loans that have a <b>high interest rate</b>(above 13.23%) are more likely to become a <b>bad loan </b>. </li>\n",
    "<li>Loans that have a longer <b> maturity date (60 months) </b> are more likely to be a bad loan. </li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "21cefe96-b94e-4fc9-966d-7b7e84b23f1e",
    "_kg_hide-input": true,
    "_uuid": "3ebf01c55a68109fca1194f13c7eabb6e6d2bd23"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the loan amount for loans that were defaulted by each region.\n",
    "northe_defaults = df['loan_amount'].loc[(df['region'] == 'NorthEast') & (df['loan_status'] == 'Default')].values.tolist()\n",
    "southw_defaults = df['loan_amount'].loc[(df['region'] == 'SouthWest') & (df['loan_status'] == 'Default')].values.tolist()\n",
    "southe_defaults = df['loan_amount'].loc[(df['region'] == 'SouthEast') & (df['loan_status'] == 'Default')].values.tolist()\n",
    "west_defaults = df['loan_amount'].loc[(df['region'] == 'West') & (df['loan_status'] == 'Default')].values.tolist()\n",
    "midw_defaults = df['loan_amount'].loc[(df['region'] == 'MidWest') & (df['loan_status'] == 'Default')].values.tolist()\n",
    "\n",
    "# Cumulative Values\n",
    "y0_stck=northe_defaults\n",
    "y1_stck=[y0+y1 for y0, y1 in zip(northe_defaults, southw_defaults)]\n",
    "y2_stck=[y0+y1+y2 for y0, y1, y2 in zip(northe_defaults, southw_defaults, southe_defaults)]\n",
    "y3_stck=[y0+y1+y2+y3 for y0, y1, y2, y3 in zip(northe_defaults, southw_defaults, southe_defaults, west_defaults)]\n",
    "y4_stck=[y0+y1+y2+y3+y4 for y0, y1, y2, y3, y4 in zip(northe_defaults, southw_defaults, southe_defaults, west_defaults, midw_defaults)] \n",
    "\n",
    "# Make original values strings and add % for hover text\n",
    "y0_txt=['$' + str(y0) for y0 in northe_defaults]\n",
    "y1_txt=['$' + str(y1) for y1 in southw_defaults]\n",
    "y2_txt=['$' + str(y2) for y2 in southe_defaults]\n",
    "y3_txt=['$' + str(y3) for y3 in west_defaults]\n",
    "y4_txt=['$'+ str(y4) for y4 in midw_defaults]\n",
    "\n",
    "year = sorted(df[\"year\"].unique().tolist())\n",
    "\n",
    "NorthEast_defaults = go.Scatter(\n",
    "    x= year,\n",
    "    y= y0_stck,\n",
    "    text=y0_txt,\n",
    "    hoverinfo='x+text',\n",
    "    name='NorthEast',\n",
    "    mode= 'lines',\n",
    "    line=dict(width=0.5,\n",
    "             color='rgb(131, 90, 241)'),\n",
    "    fill='tonexty'\n",
    ")\n",
    "SouthWest_defaults = go.Scatter(\n",
    "    x=year,\n",
    "    y=y1_stck,\n",
    "    text=y1_txt,\n",
    "    hoverinfo='x+text',\n",
    "    name='SouthWest',\n",
    "    mode= 'lines',\n",
    "    line=dict(width=0.5,\n",
    "             color='rgb(255, 140, 0)'),\n",
    "    fill='tonexty'\n",
    ")\n",
    "\n",
    "SouthEast_defaults = go.Scatter(\n",
    "    x= year,\n",
    "    y= y2_stck,\n",
    "    text=y2_txt,\n",
    "    hoverinfo='x+text',\n",
    "    name='SouthEast',\n",
    "    mode= 'lines',\n",
    "    line=dict(width=0.5,\n",
    "             color='rgb(240, 128, 128)'),\n",
    "    fill='tonexty'\n",
    ")\n",
    "\n",
    "West_defaults = go.Scatter(\n",
    "    x= year,\n",
    "    y= y3_stck,\n",
    "    text=y3_txt,\n",
    "    hoverinfo='x+text',\n",
    "    name='West',\n",
    "    mode= 'lines',\n",
    "    line=dict(width=0.5,\n",
    "             color='rgb(135, 206, 235)'),\n",
    "    fill='tonexty'\n",
    ")\n",
    "\n",
    "MidWest_defaults = go.Scatter(\n",
    "    x= year,\n",
    "    y= y4_stck,\n",
    "    text=y4_txt,\n",
    "    hoverinfo='x+text',\n",
    "    name='MidWest',\n",
    "    mode= 'lines',\n",
    "    line=dict(width=0.5,\n",
    "             color='rgb(240, 230, 140)'),\n",
    "    fill='tonexty'\n",
    "    )\n",
    "\n",
    "\n",
    "data = [NorthEast_defaults, SouthWest_defaults, SouthEast_defaults, West_defaults, MidWest_defaults]\n",
    "\n",
    "layout = dict(title = 'Amount Defaulted by Region',\n",
    "              xaxis = dict(title = 'Year'),\n",
    "              yaxis = dict(title = 'Amount Defaulted')\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "              \n",
    "iplot(fig, filename='basic-area-no-bound')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a054995e-1b03-4ebf-bf0d-f1e73c3bc4d0",
    "_uuid": "0b92e46f6497e3879c38341e03f12725bf5a9957"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04332c5a-48ad-4b93-8925-a658dce50e40",
    "_kg_hide-input": true,
    "_uuid": "1b66129c72b78775afad04857630c908089a7ca9"
   },
   "outputs": [],
   "source": [
    "df['interest_rate'].describe()\n",
    "# Average interest is 13.26% Anything above this will be considered of high risk let's see if this is true.\n",
    "df['interest_payments'] = np.nan\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col['interest_rate'] <= 13.23, 'interest_payments'] = 'Low'\n",
    "    col.loc[col['interest_rate'] > 13.23, 'interest_payments'] = 'High'\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6afd4368-f754-40f0-9e4d-cbda61ebbabe",
    "_kg_hide-input": true,
    "_uuid": "248f8252aaa9e0024e6a57f59a58d44430808a00"
   },
   "outputs": [],
   "source": [
    "df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ef845e2-3cc9-489f-a5d1-4e43d0726a4b",
    "_kg_hide-input": true,
    "_uuid": "dea4755d7bcfadfdca96f1adbeb94d44d3386b00"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "palette = ['#009393', '#930000']\n",
    "plt.subplot(221)\n",
    "ax = sns.countplot(x='interest_payments', data=df, \n",
    "                  palette=palette, hue='loan_condition')\n",
    "ax.text(0.01, .95, 'Interest Rates <= 13.23% (Low) | Interest Rates >= 13.23% (High)', fontsize=9, transform=ax.transAxes)\n",
    "\n",
    "ax.set_title('The impact of interest rate \\n on the condition of the loan', fontsize=14)\n",
    "ax.set_xlabel('Level of Interest Payments', fontsize=12)\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.subplot(222)\n",
    "ax1 = sns.countplot(x='interest_payments', data=df, \n",
    "                   palette=palette, hue='term')\n",
    "\n",
    "ax1.set_title('The impact of maturity date \\n on interest rates', fontsize=14)\n",
    "ax1.set_xlabel('Level of Interest Payments', fontsize=12)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.text(1.21, .95, 'Interest Rates <= 13.23% (Low) | Interest Rates >= 13.23% (High)', fontsize=9, transform=ax.transAxes)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "low = df['loan_amount'].loc[df['interest_payments'] == 'Low'].values\n",
    "high = df['loan_amount'].loc[df['interest_payments'] == 'High'].values\n",
    "\n",
    "\n",
    "ax2= sns.distplot(low, color='#009393', label='Low Interest Payments', fit=norm, fit_kws={\"color\":\"#483d8b\"}) # Dark Blue Norm Color\n",
    "ax3 = sns.distplot(high, color='#930000', label='High Interest Payments', fit=norm, fit_kws={\"color\":\"#c71585\"}) #  Red Norm Color\n",
    "plt.axis([0, 36000, 0, 0.00016])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa0fd7e2-870d-401d-96e5-a7c504157872",
    "_uuid": "70536045c4c088b23e82cde2d7643d4289adb0f9"
   },
   "source": [
    "## Risk Assesment:\n",
    "The main aim in this section is to compare the average interest rate for the loan status belonging to each type of loans (Good loan or bad loan) and see if there is any significant difference in the average of interest rate for each of the groups.\n",
    "\n",
    "## Summary: \n",
    "<ul>\n",
    "<li> <b> Bad Loans: </b>  Most of the loan statuses belonging to this group pay a interest ranging from 15% - 16%. </li>\n",
    "<li><b>Good Loans:</b> Most of the loan statuses belonging to this group pay interest ranging from 12% - 13%.  </li>\n",
    "<li>There has to be a better assesment of risk since there is not that much of a difference in interest payments from <b>Good Loans</b> and <b>Bad Loans</b>. </li>\n",
    "<li> Remember, most loan statuses are <b>Current</b> so there is a risk that at the end of maturity some of these loans might become bad loans. </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "\n",
    "*Credits to Zhiwen for providing an important aspect of the analysis (Relationship of interest rates and loan condition).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ba05f3a3-af80-496c-817a-35a34cbfe7bc",
    "_kg_hide-input": true,
    "_uuid": "c02adf19c2c71e052cbe3aeab7d8bd6663ef289d"
   },
   "outputs": [],
   "source": [
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Interest rate good loans\n",
    "avg_fully_paid = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Fully Paid'].values), 2)\n",
    "avg_current = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Current'].values), 2) \n",
    "avg_issued = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Issued'].values), 2)\n",
    "avg_long_fully_paid = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid'].values), 2)\n",
    "avg_grace_period = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'In Grace Period'].values), 2)\n",
    "avg_short_late = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Late (16-30 days)'].values), 2)\n",
    "avg_long_late = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Late (31-120 days)'].values), 2)\n",
    "\n",
    "\n",
    "\n",
    "# Interest rate bad loans\n",
    "\n",
    "avg_default_rates = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Default'].values), 2)\n",
    "avg_charged_off = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Charged Off'].values), 2)\n",
    "avg_long_charged_off = round(np.mean(df['interest_rate'].loc[df['loan_status'] == 'Does not meet the credit policy. Status:Charged Off'].values), 2)\n",
    "\n",
    "\n",
    "# Take to a dataframe\n",
    "\n",
    "data = [\n",
    "    go.Scatterpolar(\n",
    "        mode='lines+markers',\n",
    "      r = [avg_fully_paid, avg_current, avg_issued, avg_long_fully_paid, avg_grace_period, avg_short_late, avg_long_late],\n",
    "      theta = ['Fully Paid', 'Current', 'Issued', 'No C.P. Fully Paid','In Grace Period', 'Late (16-30 days)', 'Late (31-120 days)'],\n",
    "      fill = 'toself',\n",
    "      name = 'Good Loans',\n",
    "        line = dict(\n",
    "        color = \"#63AF63\"\n",
    "      ),\n",
    "      marker = dict(\n",
    "        color = \"#B3FFB3\",\n",
    "        symbol = \"square\",\n",
    "        size = 8\n",
    "      ),\n",
    "      subplot = \"polar\",\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        mode='lines+markers',\n",
    "      r = [avg_default_rates, avg_charged_off, avg_long_charged_off],\n",
    "      theta = ['Default Rate', 'Charged Off', 'C.P. Charged Off'], \n",
    "      fill = 'toself',\n",
    "      name = 'Bad Loans',\n",
    "        line = dict(\n",
    "        color = \"#C31414\"\n",
    "      ),\n",
    "      marker = dict(\n",
    "        color = \"#FF5050\",\n",
    "        symbol = \"square\",\n",
    "        size = 8\n",
    "      ),\n",
    "      subplot = \"polar2\"\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Average Interest Rates <br> Loan Status Distribution\",\n",
    "    showlegend = False,\n",
    "     paper_bgcolor = \"rgb(255, 248, 243)\",\n",
    "    polar = dict(\n",
    "      domain = dict(\n",
    "        x = [0,0.4],\n",
    "        y = [0,1]\n",
    "      ),\n",
    "      radialaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 8\n",
    "        )\n",
    "      ),\n",
    "      angularaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 8\n",
    "        ),\n",
    "        rotation = 90,\n",
    "        direction = \"counterclockwise\"\n",
    "      )\n",
    "    ),\n",
    "    polar2 = dict(\n",
    "      domain = dict(\n",
    "        x = [0.6,1],\n",
    "        y = [0,1]\n",
    "      ),\n",
    "      radialaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 8\n",
    "        )\n",
    "      ),\n",
    "      angularaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 8\n",
    "        ),\n",
    "        rotation = 90,\n",
    "        direction = \"clockwise\"\n",
    "      ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='polar/directions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8189c32f-bca9-4352-8970-ac3a2105f08d",
    "_uuid": "9098a5bb015b266239063777b19f5f2e96dca2c8"
   },
   "source": [
    "## Condition of Loans and Purpose:\n",
    "<a id=\"loan_condition\"></a>\n",
    "In this section we will go into depth regarding the <b>reasons for clients to apply for a loan. </b> Our main aim is to see if there are purposes that contribute to a <b> \"higher\" </b> risk whether the loan will be repaid or not.\n",
    "\n",
    "### Summary: \n",
    "<ul>\n",
    "<li> <b>Bad Loans Count: </b> People that apply for educational and small business purposed tend to have a higher risk of being a bad loan. (% wise) </li>\n",
    "<li><b>Most frequent Purpose: </b> The reason that clients applied the most for a loan was to consolidate debt. </li>\n",
    "<li><b>Less frequent purpose:</b> Clients applied less for educational purposes for all three income categories.  </li>\n",
    "<li><b>Interest Rates: </b> In all reasons for application except (medical, small business and credi card), the low income category has a higher interest rate. Something that could possibly explain this is the amount of capital that is needed from other income categories that might explain why the low income categories interest rate for these puposes are lower.  </li>\n",
    "<li><b>Bad/Good Ratio:</b> Except for educational purposes (we see a spike in high income this is due to the reasons that only two loans were issued and one was a bad loan which caused this ratio to spike to 50%.), but we can see that in all other purposed the bad good ratio is lower the higher your income category.  </li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d3f0eb2-7972-4530-ba4a-7dc972365532",
    "_kg_hide-input": true,
    "_uuid": "52ff33526a8be8df1bf1f05b351e0af03109bb7d"
   },
   "outputs": [],
   "source": [
    "df['purpose'].value_counts()\n",
    "\n",
    "# Education, renewable energy, wedding are the purposed that contains highest bad loans percent wise.\n",
    "\n",
    "purpose_condition = round(pd.crosstab(df['loan_condition'], df['purpose']).apply(lambda x: x/x.sum() * 100), 2)\n",
    "\n",
    "purpose_bad_loans = purpose_condition.values[0].tolist()\n",
    "purpose_good_loans = purpose_condition.values[1].tolist()\n",
    "purpose = purpose_condition.columns\n",
    "\n",
    "\n",
    "bad_plot = go.Bar(\n",
    "    x=purpose,\n",
    "    y=purpose_bad_loans,\n",
    "    name = 'Bad Loans',\n",
    "    text='%',\n",
    "    marker=dict(\n",
    "        color='rgba(219, 64, 82, 0.7)',\n",
    "        line = dict(\n",
    "            color='rgba(219, 64, 82, 1.0)',\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "good_plot = go.Bar(\n",
    "    x=purpose,\n",
    "    y=purpose_good_loans,\n",
    "    name='Good Loans',\n",
    "    text='%',\n",
    "    marker=dict(\n",
    "        color='rgba(50, 171, 96, 0.7)',\n",
    "        line = dict(\n",
    "            color='rgba(50, 171, 96, 1.0)',\n",
    "            width=2\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "data = [bad_plot, good_plot]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Condition of Loan by Purpose',\n",
    "    xaxis=dict(\n",
    "        title=''\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% of the Loan',\n",
    "    ),\n",
    "    paper_bgcolor='ivory',\n",
    "    plot_bgcolor='ivory',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='condition_purposes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ba370f2-b2ff-41ae-a4e4-00fd77f73a80",
    "_kg_hide-input": true,
    "_uuid": "2638cba0e0a790a96cda92a2bc17cb0071624bbd"
   },
   "outputs": [],
   "source": [
    "# Average interest by income category and purposes \n",
    "# Which purpose carries a higher interest rate and does income category have an influence on risk?\n",
    "# Is LendingClub deploying loan amount where there is a high risk (interest_rate)\n",
    "# Remember we learned that interest_rates is a key metric in evaluating risk.\n",
    "\n",
    "\n",
    "\n",
    "group_income_purpose = df.groupby(['income_category', 'purpose'], as_index=False).interest_rate.mean()\n",
    "group_dti_purpose = df.groupby(['income_category', 'purpose'], as_index=False).loan_amount.mean()\n",
    "loan_a = group_dti_purpose['loan_amount'].values\n",
    "\n",
    "\n",
    "\n",
    "# High Car 10.32 15669\n",
    "new_groupby = group_income_purpose.assign(total_loan_amount=loan_a)\n",
    "sort_group_income_purpose = new_groupby.sort_values(by=\"income_category\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cb2f9647-973d-4dd3-8300-b397f0a8d23e",
    "_kg_hide-input": true,
    "_uuid": "24b878001ff17e42f066f6bc838c19f2990b4af5"
   },
   "outputs": [],
   "source": [
    "loan_count = df.groupby(['income_category', 'purpose'])['loan_condition'].apply(lambda x: x.value_counts())\n",
    "d={\"loan_c\": loan_count}\n",
    "loan_c_df = pd.DataFrame(data=d).reset_index()\n",
    "loan_c_df = loan_c_df.rename(columns={\"level_2\": \"loan_condition\"})\n",
    "\n",
    "\n",
    "# Good loans & Bad Loans\n",
    "good_loans = loan_c_df.loc[loan_c_df['loan_condition'] == \"Good Loan\"].sort_values(by=\"income_category\", ascending=True)\n",
    "bad_loans = loan_c_df.loc[loan_c_df['loan_condition'] == \"Bad Loan\"].sort_values(by=\"income_category\", ascending=True)\n",
    "sort_group_income_purpose['good_loans_count'] = good_loans['loan_c'].values\n",
    "sort_group_income_purpose['bad_loans_count'] = bad_loans['loan_c'].values\n",
    "sort_group_income_purpose['total_loans_issued'] = (good_loans['loan_c'].values + bad_loans['loan_c'].values)\n",
    "sort_group_income_purpose['bad/good ratio (%)'] = np.around(bad_loans['loan_c'].values / (bad_loans['loan_c'].values + good_loans['loan_c'].values), 4) * 100\n",
    "final_df = sort_group_income_purpose.sort_values(by='income_category', ascending=True)\n",
    "final_df.style.background_gradient('coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "712f0414c0383e9bd13b23e75277cc4da71c758b"
   },
   "outputs": [],
   "source": [
    "final_df = final_df.sort_values(by=\"purpose\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "51a0211b7167f3db6125376369f2a11273103b19"
   },
   "outputs": [],
   "source": [
    "# Work on a plot to explain better the correlations between the different columns in final_df dataframe.\n",
    "# We will do a Subplot in Plotly with \n",
    "\n",
    "#import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Labels\n",
    "purpose_labels = df['purpose'].unique()\n",
    "\n",
    "# Average Interest Rate Dot Plots # 1st Subplot\n",
    "high_income = final_df['interest_rate'].loc[final_df['income_category'] == 'High'].values.tolist()\n",
    "medium_income = final_df['interest_rate'].loc[final_df['income_category'] == 'Medium'].values.tolist()\n",
    "low_income = final_df['interest_rate'].loc[final_df['income_category'] == 'Low'].values.tolist()\n",
    "\n",
    "high_lst = ['%.2f' % val for val in high_income]\n",
    "med_lst = ['%.2f' % val for val in medium_income]\n",
    "low_lst = ['%.2f' % val for val in low_income]\n",
    "\n",
    "\n",
    "\n",
    "trace1 = {\"x\": high_lst,\n",
    "          \"y\": purpose_labels,\n",
    "          \"marker\": {\"color\": \"#0040FF\", \"size\": 16},\n",
    "          \"mode\": \"markers\",\n",
    "          \"name\": \"High Income\",\n",
    "          \"type\": \"scatter\"\n",
    "}\n",
    "\n",
    "trace2 = {\"x\": med_lst,\n",
    "          \"y\": purpose_labels,\n",
    "          \"marker\": {\"color\": \"#FE9A2E\", \"size\": 16},\n",
    "          \"mode\": \"markers\",\n",
    "          \"name\": \"Medium Income\",\n",
    "          \"type\": \"scatter\",\n",
    "}\n",
    "\n",
    "trace3 = {\"x\": low_lst,\n",
    "          \"y\": purpose_labels,\n",
    "          \"marker\": {\"color\": \"#FE2E2E\", \"size\": 16},\n",
    "          \"mode\": \"markers\",\n",
    "          \"name\": \"Low Income\",\n",
    "          \"type\": \"scatter\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "layout = {\"title\": \"Average Purpose Interest Rate <br> <i> by Income Category </i> \",\n",
    "          \"xaxis\": {\"title\": \"Average Interest Rate\", },\n",
    "          \"yaxis\": {\"title\": \"\"}}\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "afcd4c0aa4bcb61eb234c0b3f7e9eaf843064d83"
   },
   "outputs": [],
   "source": [
    "# Labels\n",
    "purpose_labels = final_df['purpose'].unique()\n",
    "\n",
    "# Amount of Good and Bad Loans per Purpose (fill by income category)\n",
    "# Good Loans\n",
    "good_high_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"High\"].values.tolist()\n",
    "good_med_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"Medium\"].values.tolist()\n",
    "good_low_cnt = final_df['good_loans_count'].loc[final_df['income_category'] == \"Low\"].values.tolist()\n",
    "\n",
    "# Bad Loans\n",
    "bad_high_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"High\"].values.tolist()\n",
    "bad_med_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"Medium\"].values.tolist()\n",
    "bad_low_cnt = final_df['bad_loans_count'].loc[final_df['income_category'] == \"Low\"].values.tolist()\n",
    "\n",
    "\n",
    "# Good Loans\n",
    "trace0 = go.Bar(\n",
    "    y=purpose_labels,\n",
    "    x=good_high_cnt,\n",
    "    legendgroup='a',\n",
    "    name='High Income',\n",
    "    orientation='h', \n",
    "    marker=dict(\n",
    "        color='#0040FF'\n",
    "    )\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=good_med_cnt,\n",
    "    y=purpose_labels,\n",
    "    legendgroup='a',\n",
    "    name='Medium Income',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='#FE9A2E',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=good_low_cnt,\n",
    "    y=purpose_labels,\n",
    "    legendgroup='a',\n",
    "    name='Low Income',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='#FE2E2E',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Bad Loans issued by Income Category\n",
    "trace3 = go.Bar(\n",
    "    y=purpose_labels,\n",
    "    x=bad_high_cnt,\n",
    "    legendgroup='b',\n",
    "    showlegend=False,\n",
    "    name='High Income',\n",
    "    orientation='h', \n",
    "    marker=dict(\n",
    "        color='#0040FF'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Bar(\n",
    "    x=bad_med_cnt,\n",
    "    y=purpose_labels,\n",
    "    legendgroup='b',\n",
    "    showlegend=False,\n",
    "    name='Medium Income',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='#FE9A2E',\n",
    "    )\n",
    ")\n",
    "\n",
    "trace5 = go.Bar(\n",
    "    x=bad_low_cnt,\n",
    "    y=purpose_labels,\n",
    "    legendgroup='b',\n",
    "    showlegend=False,\n",
    "    name='Low Income',\n",
    "    orientation='h',\n",
    "    marker=dict(\n",
    "        color='#FE2E2E',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=1, print_grid=False,\n",
    "                         subplot_titles=(\"Amount of <br> <i>Good Loans Issued</i>\",\n",
    "                                        \"Amount of <br> <i>Bad Loans Issued</i>\")\n",
    "                         )\n",
    "\n",
    "# First Subplot\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 1)\n",
    "\n",
    "# Second Subplot\n",
    "fig.append_trace(trace3, 2, 1)\n",
    "fig.append_trace(trace4, 2, 1)\n",
    "fig.append_trace(trace5, 2, 1)\n",
    "\n",
    "fig['layout'].update(height=800, width=800, title='Issuance of Loans', showlegend=True, xaxis=dict(title=\"Number of Loans Issued\"))\n",
    "iplot(fig, filename='angled-text-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "a52a906925bf332dca15f1bbd4f2ce1463f90e0c"
   },
   "outputs": [],
   "source": [
    "# Next task a Radar Chart with the bad/good ratio to see if it justifies the amount of loans issued towards housing\n",
    "high_ratio = final_df.loc[final_df['income_category'] == 'High']\n",
    "medium_ratio = final_df.loc[final_df['income_category'] == 'Medium']\n",
    "low_ratio = final_df.loc[final_df['income_category'] == 'Low']\n",
    "\n",
    "data = [\n",
    "    go.Scatterpolar(\n",
    "        mode='lines+markers',\n",
    "      r = high_ratio['bad/good ratio (%)'].values.tolist(),\n",
    "      theta = high_ratio['purpose'].unique(),\n",
    "      fill = 'toself',\n",
    "      name = 'High Income',\n",
    "        line = dict(\n",
    "        color = \"#63AF63\"\n",
    "      ),\n",
    "      marker = dict(\n",
    "        color = \"#B3FFB3\",\n",
    "        symbol = \"square\",\n",
    "        size = 8\n",
    "      ),\n",
    "      subplot = \"polar\",\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        mode='lines+markers',\n",
    "      r = medium_ratio['bad/good ratio (%)'].values.tolist(),\n",
    "      theta = medium_ratio['purpose'].unique(),\n",
    "      fill = 'toself',\n",
    "      name = 'Medium Income',\n",
    "        line = dict(\n",
    "        color = \"#C31414\"\n",
    "      ),\n",
    "      marker = dict(\n",
    "        color = \"#FF5050\",\n",
    "        symbol = \"square\",\n",
    "        size = 8\n",
    "      ),\n",
    "      subplot = \"polar2\"\n",
    "    ),\n",
    "    go.Scatterpolar(\n",
    "        mode='lines+markers',\n",
    "      r = low_ratio['bad/good ratio (%)'].values.tolist(),\n",
    "      theta = low_ratio['purpose'].unique(),\n",
    "      fill = 'toself',\n",
    "      name = 'Low Income',\n",
    "        line = dict(\n",
    "        color = \"#C9FFC7\"\n",
    "      ),\n",
    "      marker = dict(\n",
    "        color = \"#8CB28B\",\n",
    "        symbol = \"square\",\n",
    "        size = 8\n",
    "      ),\n",
    "      subplot = \"polar3\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Bad/Good Ratio <br> (By Purpose)\",\n",
    "    showlegend = False,\n",
    "     paper_bgcolor = \"rgb(255, 206, 153)\",\n",
    "    polar = dict(\n",
    "      domain = dict(\n",
    "        x = [0,0.3],\n",
    "        y = [0,1]\n",
    "      ),\n",
    "      radialaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        )\n",
    "      ),\n",
    "      angularaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        ),\n",
    "        rotation = 90,\n",
    "        direction = \"counterclockwise\"\n",
    "      )\n",
    "    ),\n",
    "    polar2 = dict(\n",
    "      domain = dict(\n",
    "        x = [0.35,0.65],\n",
    "        y = [0,1]\n",
    "      ),\n",
    "      radialaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        )\n",
    "      ),\n",
    "      angularaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        ),\n",
    "        rotation = 85,\n",
    "        direction = \"clockwise\"\n",
    "      ),\n",
    "    ),\n",
    "    polar3 = dict(\n",
    "      domain = dict(\n",
    "        x = [0.7, 1],\n",
    "        y = [0,1]\n",
    "      ),\n",
    "      radialaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        )\n",
    "      ),\n",
    "      angularaxis = dict(\n",
    "        tickfont = dict(\n",
    "          size = 6\n",
    "        ),\n",
    "        rotation = 90,\n",
    "        direction = \"clockwise\"\n",
    "      ),\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename = \"radar/multiple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "86754a74-044f-4a11-99dd-558c698348c8",
    "_uuid": "b7a23547860a6523e22df9d2ece313c10dc64190"
   },
   "source": [
    "## Feature Engineering and Neural Network:\n",
    "**Steps:**\n",
    "<ul>\n",
    "<li> There are <b> features </b> that are redundant (as show in the beginning of this kernel in the distribution subplots) having no effect towards the \"loan_condition\" label so we need to <b> drop these features</b>.</li><br>\n",
    "<li> Use <b>StrattifiedShuffleSplit</b> to have approximately the same ratio of bad loans compared to good loans in both training and testing data. Remember that over 92% of the loans are considered good loans so it is important to have this same ration across training and testing sets. </li>\n",
    "<li> <b>Scale </b> numeric features and <b>encode</b> categorical features from our dataframe. </li>\n",
    "<li> Run our Neural Network containing the number of inputs, 2 hidden layers (first: 15 nodes, second: 5 nodes) and the number of outputs which is equivalent to 2.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If you want to skip to this:\n",
    "\n",
    "#df = pd.read_csv('df.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loan_condition.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Null Values:\n",
    "1) Find those variables with more than 20% nulls\n",
    "2) Compare list of null counts across good vs bad loans to make sure the same variables meet that threshold in the good group as in the bad\n",
    "3) Evaluate nulls by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Whole dataset null count\n",
    "\n",
    "nulls = pd.DataFrame(round(complete_df.isnull().sum()/len(complete_df.index)*100,2),columns=['null_percent'])\n",
    " \n",
    "null_prct = nulls[nulls['null_percent']!=0.00].sort_values('null_percent',ascending=False)\n",
    "null_prct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Good Loans dataset null count\n",
    "\n",
    "nulls_good = pd.DataFrame(round(complete_df[complete_df.loan_condition == 'Good Loan'].isnull().sum()/len(complete_df[complete_df.loan_condition == 'Good Loan'].index)*100,2),columns=['null_percent'])\n",
    "\n",
    "null_prct_good = nulls_good[nulls_good['null_percent']!=0.00].sort_values('null_percent',ascending=False)\n",
    "null_prct_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bad Loans dataset null count\n",
    "\n",
    "nulls_bad = pd.DataFrame(round(complete_df[complete_df.loan_condition == 'Bad Loan'].isnull().sum()/len(complete_df[complete_df.loan_condition == 'Bad Loan'].index)*100,2),columns=['null_percent'])\n",
    "\n",
    "null_prct_bad = nulls_bad[nulls_bad['null_percent']!=0.00].sort_values('null_percent',ascending=False)\n",
    "null_prct_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variables with >20% nulls are the same for both good and bad subsets\n",
    "\n",
    "rm_good = list(null_prct_good[null_prct_good.null_percent > 20].index)\n",
    "rm_bad = list(null_prct_bad[null_prct_bad.null_percent > 20].index)\n",
    "\n",
    "print(len(rm_good))\n",
    "print(len(rm_bad))\n",
    "print(list(set(rm_good)-set(rm_bad)))\n",
    "print(list(set(rm_good).symmetric_difference(set(rm_bad))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping above variables\n",
    "\n",
    "print(complete_df.shape)\n",
    "complete_df.drop(rm_good, axis=1, inplace=True)\n",
    "print(complete_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#termining other unnecessaries to drop: loan_condition cause we have loan_condition_int flag\n",
    "complete_df.drop(['loan_condition','complete_date'], axis=1, inplace = True)\n",
    "\n",
    "list(complete_df.columns.sort_values().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Visualizing the distribution of nulls\n",
    "complete_df = complete_df.reset_index(drop=True) #resetting index for easier row identification\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "sns.heatmap(complete_df.isna(),cmap='viridis')\n",
    "\n",
    "#As we can see here nulls are concentrated in two small grouping of rows. \n",
    "#The trick will be finding those rows and removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting index due to boxing of row issues below\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finding rows with 'high null density' to decide if they should be removed \n",
    "\n",
    "#Null Cluster Group A\n",
    "groupA = complete_df.iloc[1611859:1654394]\n",
    "groupA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good = 0 | Bad = 1\n",
    "\n",
    "groupA.groupby('year').loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.groupby('year').loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupA.loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total bad records(GroupA):\n",
    "\n",
    "groupA.loan_condition_int.value_counts()[1]/complete_df.loan_condition_int.value_counts()[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total good records(GroupA):\n",
    "\n",
    "groupA.loan_condition_int.value_counts()[0]/complete_df.loan_condition_int.value_counts()[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullgrpa = pd.DataFrame(round(groupA.isnull().sum()/len(groupA.index)*100,2),columns=['null_percent'])\n",
    "\n",
    "null_prct_grpa = nullgrpa[nullgrpa['null_percent']!=0.00].sort_values('null_percent',ascending=False)\n",
    "null_prct_grpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_list_a = list(null_prct_grpa[null_prct_grpa.null_percent > 20].index)\n",
    "len(rm_list_a)/len(groupA.columns)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null GroupA Findings:\n",
    "- Consists of all loans in years 2007-2011\n",
    "- 36% of all columns in Group A are missing all values\n",
    "- Group A Records consist of 1.8% of good loans and 2.4% of bad loans\n",
    "- Decision: Drop Group A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Null Cluster (Group B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finding Null Cluster (Group B)\n",
    "\n",
    "groupB = complete_df.iloc[1911777:1939354]\n",
    "groupB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Good = 0 | Bad = 1\n",
    "\n",
    "groupB.groupby('year').loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.groupby('year').loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupB.loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.loan_condition_int.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total bad records(GroupB):\n",
    "\n",
    "groupB.loan_condition_int.value_counts()[1]/complete_df.loan_condition_int.value_counts()[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total good records (GroupB):\n",
    "\n",
    "groupB.loan_condition_int.value_counts()[0]/complete_df.loan_condition_int.value_counts()[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total bad records (Group A & B):\n",
    "\n",
    "(groupA.loan_condition_int.value_counts()[1] + groupB.loan_condition_int.value_counts()[1])/complete_df.loan_condition_int.value_counts()[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of total good records (Group A & B):\n",
    "\n",
    "(groupA.loan_condition_int.value_counts()[0] + groupB.loan_condition_int.value_counts()[0])/complete_df.loan_condition_int.value_counts()[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullgrpb = pd.DataFrame(round(groupB.isnull().sum()/len(groupB.index)*100,2),columns=['null_percent'])\n",
    "\n",
    "null_prct_grpb = nullgrpb[nullgrpb['null_percent']!=0.00].sort_values('null_percent',ascending=False)\n",
    "null_prct_grpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_list_b = list(null_prct_grpb[null_prct_grpb.null_percent > 20].index)\n",
    "len(rm_list_b)/len(groupB.columns)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null GroupB Findings:\n",
    "- Consists of 50% of loans in years 2012\n",
    "- 36% of all columns in Group B are missing all values\n",
    "- Group B Records consist of 1.15% of good loans and 1.7% of bad loans\n",
    "- Group A & B consist of 2.96% of good loans and 4.1% of bad loans\n",
    "- Decision: Drop Group B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Group A & B from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GroupA:', complete_df.iloc[1611859:1654394].shape)\n",
    "print('GroupB:', complete_df.iloc[1911777:1939354].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42535+27577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving complete_df\n",
    "\n",
    "complete_df.to_csv('complete_df.csv', index_label = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before:', complete_df.shape)\n",
    "\n",
    "#This drops Group A & B\n",
    "complete_df = complete_df.drop(complete_df.index[1611859:1654394], axis = 0).drop(complete_df.index[1911777:1939354], axis = 0)\n",
    "                                                                            #part B\n",
    "print('After:', complete_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2260668-2190556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualizing the distribution of nulls\n",
    "# #complete_df = complete_df.reset_index(drop=True) \n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "sns.heatmap(complete_df.isna(),cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes to self: Pull out month from issue date and delete issue_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = complete_df.copy()\n",
    "# x['month'] = x.issue_d.apply(lambda x: x.split('-'))[0]\n",
    "# x['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling In Remaining Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[\"delinq_2yrs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mode of next payment date and last payment date and the last date credit amount was pulled   \n",
    "#complete_df[\"next_pymnt_d\"] = complete_df.groupby(\"region\")[\"next_pymnt_d\"].transform(lambda x: x.fillna(x.mode))\n",
    "\n",
    "complete_df[\"last_pymnt_d\"] = complete_df.groupby(\"region\")[\"last_pymnt_d\"].transform(lambda x: x.fillna(x.mode))\n",
    "complete_df[\"last_credit_pull_d\"] = complete_df.groupby(\"region\")[\"last_credit_pull_d\"].transform(lambda x: x.fillna(x.mode))\n",
    "complete_df[\"earliest_cr_line\"] = complete_df.groupby(\"region\")[\"earliest_cr_line\"].transform(lambda x: x.fillna(x.mode))\n",
    "\n",
    "# # # Get the mode on the number of accounts in which the client is delinquent\n",
    "complete_df[\"pub_rec\"] = complete_df.groupby(\"region\")[\"pub_rec\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# # # Get the mean of the annual income depending in the region the client is located.\n",
    "complete_df[\"annual_income\"] = complete_df.groupby(\"region\")[\"annual_income\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# # Get the mode of the  total number of credit lines the borrower has \n",
    "complete_df[\"total_acc\"] = complete_df.groupby(\"region\")[\"total_acc\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# # Mode of credit delinquencies in the past two years.\n",
    "complete_df[\"delinq_2yrs\"] = complete_df.groupby(\"region\")[\"delinq_2yrs\"].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_list = list(complete_df.select_dtypes(['float64','int64']).columns)\n",
    "numeric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in numeric variables with \n",
    "\n",
    "for col in (numeric_list):\n",
    "    complete_df[col] = complete_df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_list = list(complete_df.select_dtypes('object').columns)\n",
    "object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling in object variables with \n",
    "\n",
    "for col in (object_list):\n",
    "    complete_df[col] = complete_df[col].fillna('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d03e37e6-35e7-48b6-a7a8-57b515f391a8",
    "_kg_hide-input": true,
    "_uuid": "134b552c4c33951fd33fd4f812737d83cfae4df9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking for nulls\n",
    "\n",
    "complete_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Categoricals into One Hot Vectors and Scaling Numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0615a43e-e8aa-43b8-a7d6-6ccb81d4d1d7",
    "_kg_hide-input": true,
    "_uuid": "14b2e96a1908af575061200f6bf09d9adcae86ac"
   },
   "outputs": [],
   "source": [
    "# Let's make a copy of the dataframe to avoid confusion.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "len(complete_df['loan_condition_int'])\n",
    "# Loan Ratios (Imbalanced classes)\n",
    "complete_df['loan_condition_int'].value_counts()/len(complete_df['loan_condition_int']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0656a46f-77e9-4a8e-af8f-8b75010d47ba",
    "_uuid": "96c13f3db727269c9284b528d1c8c861233f2c74"
   },
   "source": [
    "The purpose of the code below is to have the same ratio across our training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "19d69a00-f76e-4ec2-aced-5da11baedffb",
    "_kg_hide-input": true,
    "_uuid": "b980cb9a5f4aed482cbb886be2c7ca5d56da7608"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_set, test_set in stratified.split(complete_df, complete_df[\"loan_condition_int\"]):\n",
    "    stratified_train = complete_df.iloc[train_set]\n",
    "    stratified_test = complete_df.iloc[test_set]\n",
    "    \n",
    "print('Train set ratio \\n', stratified_train[\"loan_condition_int\"].value_counts()/len(complete_df))\n",
    "print('Test set ratio \\n', stratified_test[\"loan_condition_int\"].value_counts()/len(complete_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "\n",
    "for test_set, holdout_set in stratified.split(stratified_test, stratified_test[\"loan_condition_int\"]):\n",
    "    stratified_test_final = stratified_test.iloc[test_set]\n",
    "    stratified_holdout = stratified_test.iloc[holdout_set]\n",
    "    \n",
    "print('Test set ratio \\n', stratified_test_final[\"loan_condition_int\"].value_counts()/len(stratified_test))\n",
    "print('Holdout set ratio \\n', stratified_holdout[\"loan_condition_int\"].value_counts()/len(stratified_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Set % of Total:', round((len(stratified_train)/len(complete_df)*100),2))\n",
    "print('Test Set % of Total:', round((len(stratified_test_final)/len(complete_df)*100),2))\n",
    "print('Holdout Set % of Total:', round((len(stratified_holdout)/len(complete_df)*100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = stratified_train.copy()\n",
    "test_df = stratified_test_final.copy()\n",
    "holdout_df = stratified_holdout.copy()\n",
    "\n",
    "train_df.to_csv('train_df.csv', index_label = 'index')\n",
    "test_df.to_csv('test_df.csv', index_label = 'index')\n",
    "holdout_df.to_csv('holdout_df.csv', index_label = 'index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
